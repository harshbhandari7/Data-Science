{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pandas_basics",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### **Why pandas**\n",
        "\n",
        " - Flexibility of python.\n",
        " - Easier to work with big amount of data(where excels slows down and fails).\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "kQUDjLHShAwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Loading data**\n",
        "\n",
        "**Data file used for the below exercise is - 'pokemon_data.csv'**\n",
        "\n",
        "You can find it in the /data_files folder at root."
      ],
      "metadata": {
        "id": "WI3k1dAThsZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "BT0bVjR2hvWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read_csv\n",
        "# index_col -> to change make a col as an index\n",
        "# parse_dates -> parse the index\n",
        "\n",
        "pd.read_csv('filename', index_col='Dates', parse_dates=True)"
      ],
      "metadata": {
        "id": "EhQK_dNoJ8qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload file functionality through google colab libs\n",
        "\n",
        "# from google.colab import files\n",
        "# import io\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# read csv files and storing file data in a data frame\n",
        "# poke_df = pd.read_csv(io.BytesIO(uploaded['pokemon_data.csv']))\n",
        "\n",
        "# read xls, xlsx files\n",
        "# poke_df_xl = pd.read_excel(io.BytesIO(uploaded['pokemon_data.xlsx']))\n",
        "\n",
        "# read txt files - need to pass delimiter by which values are separated in the read_csv func \n",
        "# poke_df_txt = pd.read_csv(io.BytesIO(uploaded['pokemon_data.txt']), delimiter='\\t')"
      ],
      "metadata": {
        "id": "rgCnd4uchx9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Checking the data**"
      ],
      "metadata": {
        "id": "eZvLTQ9lbhNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poke_df.head() # get starting 5 rows.\n",
        "poke_df.head(7) # get 7 rows from start\n",
        "poke_df.tail() # get 5 rows from end\n",
        "poke_df.tail(10) # get 10 rows from end"
      ],
      "metadata": {
        "id": "fFWvoSKnmtSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# headers\n",
        "headers = poke_df.columns\n",
        "\n",
        "# reading specific columns\n",
        "\n",
        "cols = poke_df['Name']  # reading single col\n",
        "cols = poke_df[['Name', 'Attack', 'Defense']]   # multiple cols at once\n",
        "cols = poke_df[['Name', 'Attack']][:]  # top 5 rows\n"
      ],
      "metadata": {
        "id": "vBDOUeECprai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols"
      ],
      "metadata": {
        "id": "xKNDYOKt0kvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  reading rows\n",
        "\n",
        " #through head or tail\n",
        "poke_df.head(5)\n",
        "\n",
        "# through iloc integer location\n",
        "poke_df.iloc[5:10]\n",
        "\n",
        "# read a specific loaction (R,C)\n",
        "poke_df.iloc[0,1]\n",
        "\n",
        "# loc - used to find data based on some key basically not through index\n",
        "# poke_df.iloc[0,'Type 1']\n"
      ],
      "metadata": {
        "id": "-emaBrHE9ngX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# way to iterate\n",
        "for index, row in poke_df.iterrows():\n",
        "  print(index, row['Name'])"
      ],
      "metadata": {
        "id": "7RPs6JO19fd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# describe data - gives out all the details about the data\n",
        "poke_df.describe()"
      ],
      "metadata": {
        "id": "TCs9xZi6_UyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Sorting**"
      ],
      "metadata": {
        "id": "Ks-c7wGEE3uR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ascending sort by col named 'Name' and Type 1\n",
        "poke_df.sort_values('Name')\n",
        "poke_df.sort_values('Type 1')\n",
        "\n",
        "# to sort by descending order, we need to pass ascending False\n",
        "poke_df.sort_values('Name', ascending=False)\n",
        "\n",
        "# sorting on multiple columns and managing order\n",
        "\n",
        "poke_df.sort_values(['Name', 'Type 1'], ascending=[1, 0]) # sorts data by ascending names and descending Type 1"
      ],
      "metadata": {
        "id": "4XAS8FG9_SJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Making Changes to the Data**"
      ],
      "metadata": {
        "id": "RxmwtWjpHahj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = list(poke_df.columns.values)[4:10]\n",
        "\n",
        "# adding new col\n",
        "poke_df['Total'] = poke_df[cols].sum(axis=1)\n",
        "\n",
        "poke_df['random col'] = 0\n",
        "\n",
        "# deleting a column\n",
        "poke_df = poke_df.drop(columns=['random col'])\n",
        "\n",
        "# reordering columns\n",
        "all_cols = list(poke_df.columns)\n",
        "poke_df = poke_df[all_cols[0:4] + [all_cols[-1]] + all_cols[4:10]]"
      ],
      "metadata": {
        "id": "PfzckpZ7HfOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Saving data into csv, excel or txt file**"
      ],
      "metadata": {
        "id": "OGYTpSsrP1IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving and exporting the data to the csv file\n",
        "poke_df.to_csv('modified_data.csv') # saves the index as well in the file\n",
        "\n",
        "# if we dont wanna save the index\n",
        "poke_df.to_csv('file_name.csv', index=False)\n",
        "\n",
        "# saving data in excel\n",
        "poke_df.to_excel('file_name.xlsx', index=False)\n",
        "\n",
        "# saving data in txt\n",
        "poke_df.to_csv('file_name.txt', index=False, sep='\\t')"
      ],
      "metadata": {
        "id": "7_kODmPGK4zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Filtering Data**"
      ],
      "metadata": {
        "id": "lzql0WrJWwiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  through loc\n",
        "filtered_poke_df = poke_df.loc[(poke_df['Type 1'] == 'Grass') & (poke_df['Type 2'] == 'Poison') & (poke_df['HP'] > 70)]\n",
        "\n",
        "# resetting index on the filtered data\n",
        "\n",
        "# below will store the old index in a col name index\n",
        "filtered_poke_df_ind = filtered_poke_df.reset_index()\n",
        "\n",
        "# to completely reset the index without storing it\n",
        "filtered_poke_df = filtered_poke_df.reset_index(drop=True)\n",
        "\n",
        "# resetting, droping index inplace\n",
        "filtered_poke_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "YJ7JNhPHQobR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_poke_df"
      ],
      "metadata": {
        "id": "5EHmUszCW9R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering based on textual patterns (Regex Filtering)\n",
        "\n",
        "# filtering out all the pokemons which have Mega in their names\n",
        "# ~ is used for negation\n",
        "\n",
        "poke_df.loc[~poke_df['Name'].str.contains('Mega')]\n"
      ],
      "metadata": {
        "id": "5Gado6jtZ0cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering all the rows which have type fire or grass\n",
        "import re\n",
        "\n",
        "# in flags re.I stands for ignoring case\n",
        "\n",
        "poke_df.loc[(poke_df['Type 1'].str.contains('fire|grass', flags=re.I, regex=True))]"
      ],
      "metadata": {
        "id": "oFwgH2VjcgBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering all the names those start with pi\n",
        "\n",
        "pi_poke_df = poke_df.loc[poke_df['Name'].str.contains('^pi[a-z]*', flags=re.I, regex=True)]\n",
        "pi_poke_df.sort_values('Name', ascending=False)"
      ],
      "metadata": {
        "id": "RN34CG0Kf4D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Conditional Changes**"
      ],
      "metadata": {
        "id": "ACnBaIT1oiqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# changing Type 1 Values which are Fire to Flamer\n",
        "\n",
        "poke_df.loc[poke_df['Type 1'] == 'Fire', 'Type 1'] = 'Flamer'"
      ],
      "metadata": {
        "id": "o2taOMB2gTrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making all pokemons Legendary whose Type 1 is Rock\n",
        "\n",
        "poke_df.loc[poke_df['Type 1'] == 'Rock', 'Legendary'] = True"
      ],
      "metadata": {
        "id": "UxQAzFlCpWhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poke_df"
      ],
      "metadata": {
        "id": "LZsQO2DkpXpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Aggregate Statistics Using Group By**"
      ],
      "metadata": {
        "id": "jUobKP1ErjUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# groups by Type 1 and calculates mean value of each col for every type\n",
        "poke_df.groupby(['Type 1']).mean().sort_values('Attack', ascending=False)"
      ],
      "metadata": {
        "id": "s8bAFvtTqhrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count\n",
        "\n",
        "# setting count col to 1 for each row\n",
        "poke_df['count'] = 1\n",
        "\n",
        "count_data = poke_df.groupby(['Type 1', 'Type 2']).count()['count']"
      ],
      "metadata": {
        "id": "EFO7vVYRt-p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Working with large amount of data**"
      ],
      "metadata": {
        "id": "cBOb8Yke2poV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read data from file size in chunks\n",
        "\n",
        "# chunk size -> no of rows\n",
        "for df in pd.read_csv('filename.csv', chunksize=10):\n",
        "  print('DF CHUNK', df)"
      ],
      "metadata": {
        "id": "1-GSQYWRuEA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dvgZYF1B2LVg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}