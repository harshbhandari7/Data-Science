{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA_Summary",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis**\n",
        "\n",
        "Exploratory Data Analysis refers to the critical process of performing initial investigations on data so as to,\n",
        "- discover patterns,\n",
        "- spot anomalies,\n",
        "- test hypothesis, and\n",
        "- check assumptions with the help of summary statistics and graphical representations.\n",
        "\n",
        "It is a good practice to understand the data first and try to gather as many insights from it.\n",
        "\n",
        "EDA is all about making sense of data in hand,\n",
        "before getting them dirty with it.\n"
      ],
      "metadata": {
        "id": "Xj1ll-3YE68p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EDA Steps**\n",
        "\n",
        "\n",
        "\n",
        "1.   Data Sourcing\n",
        "2.   Data Cleaning\n",
        "3.   Univariate Analysis\n",
        "4.   Bivariate and Multivariate Analysis\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "85w-LHK2zAee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **A. Data Sourcing**\n",
        "\n",
        "- Source the data from file, querying from DB or scrapping.\n",
        "- To determine whether the data is public or private."
      ],
      "metadata": {
        "id": "YSuJ15fr2iq1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **B. Data Cleaning**\n",
        "\n",
        "Once you source the data, it is essential to get rid of the irregularities in the data and fix it to improve its quality.\n",
        "\n",
        "One can encounter different kinds of issues in a dataset. Irregularities may appear in the form of ***missing values, anomalies/outliers, incorrect format and inconsistent spelling, etc***.\n",
        "\n",
        "These irregularities may propagate further and affect the assumptions and analysis based on that dataset and may hamper the further process of machine learning model building. Hence, data cleaning is a very important step in EDA.\n",
        "\n",
        "Though data cleaning is often done in a somewhat haphazard manner, and it is difficult to define a ‘single structured process’, you will study data cleaning through the following steps:\n",
        "\n",
        "1. Identifying the data types\n",
        "\n",
        "2. Fixing the rows and columns\n",
        "\n",
        "3. Imputing/removing missing values\n",
        "\n",
        "4. Handling outliers\n",
        "\n",
        "5. Standardising the values\n",
        "\n",
        "6. Fixing invalid values\n",
        "\n",
        "7. Filtering the data"
      ],
      "metadata": {
        "id": "ChOlRvKs2kOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Identifying the data type.**\n",
        "\n",
        "Exploring the data set and finding out the columns and datatypes of those columns.\n",
        "\n",
        "How is the data stored, can we split a column into more than 1 col or combine multiple columns into 1"
      ],
      "metadata": {
        "id": "MDNCMfeP2kQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. Fixing the rows and columns**\n",
        "\n",
        "**Checklist for fixing rows:**\n",
        "\n",
        "- Delete summary rows: Total and Subtotal rows\n",
        "- Delete incorrect rows: Header row and footer row\n",
        "- Delete extra rows: Column number, indicators, blank rows, page number.\n",
        "\n",
        "**Checklist for fixing columns:**\n",
        "\n",
        "- if needed, merge columns for creating unique identifiers, for example, merge the columns State and City into the column Full Address.\n",
        "\n",
        "- Split columns to get more data: Split the Address column to get State and City columns to analyse each separately. \n",
        "\n",
        "- Add column names: Add column names if missing.\n",
        "\n",
        "- Rename columns consistently: Abbreviations, encoded columns.\n",
        "\n",
        "- Delete columns: Delete unnecessary columns.\n",
        "\n",
        "- Align misaligned columns: The data set may have shifted columns, which you need to align correctly.\n",
        "\n"
      ],
      "metadata": {
        "id": "kRDfIMeLj7IX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. Imputing/removing missing values**\n",
        "\n",
        "- Set values as missing values: Identify values that indicate missing data, for example, treat blank strings \"NA\", \"XX\", \"999\", etc., as missing.\n",
        "\n",
        "- Adding is good, exaggerating is bad: You should try to get information from reliable external sources as much as possible, but if you can’t, then it is better to retain missing values rather than exaggerating the existing rows/columns.\n",
        "\n",
        "- Delete rows and columns: Rows can be deleted if the number of missing values is insignificant, as this would not impact the overall analysis results. Columns can be removed if the missing values are significant in number.\n",
        "\n",
        "- Fill partial missing values using business judgement: Such values include missing time zones, century, etc. These values can be identified easily.\n",
        "\n",
        "**Types of missing values:**\n",
        "\n",
        "- MCAR: It stands for Missing completely at random. The reason behind the missing value is not dependent on any other features.\n",
        "\n",
        "- MAR: It stands for Missing at random. The reason behind the missing value may be associated with some other features.\n",
        "\n",
        "- MNAR: It stands for Missing not at random. There is a specific reason behind the missing value.\n",
        "\n",
        "\n",
        "## **Missing value doesn't always have to be present as null**\n",
        "\n",
        "***The various ways to impute the missing values -***\n",
        "\n",
        "**Imputation on categorical/numeric columns:**\n",
        "\n",
        "1. Categorical column: \n",
        "\n",
        "- Impute the most popular category.\n",
        "\n",
        "- Imputation can be done using logistic regression techniques.\n",
        "\n",
        "2. Numerical column:\n",
        "\n",
        "- Impute the missing value with mean/median/mode.\n",
        "\n",
        "- The other methods to impute the missing values involve the use of interpolation, linear regression. These methods are useful for continuous numerical variables."
      ],
      "metadata": {
        "id": "L_Pus0vYwJ6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4. Handling Outliers**\n",
        "\n",
        "Outliers are values that are much beyond or far from the next nearest data points.\n",
        "\n",
        "There are two types of outliers. These are:\n",
        "\n",
        "**Univariate outliers:** Univariate outliers are those data points in a variable whose values lie beyond the range of expected values. You can get a better understanding of univariate outliers from the image below. Here, almost all the points lie between 0 and 5.0, and one point is extremely far away (at 20.0) from the normal norms of this data set.\n",
        "\n",
        "**Multivariate outliers:** While plotting data, some values of one variable may not lie beyond the expected range, but when you plot the data with some other variable, these values may lie far from the expected value. These are called multivariate outliers. You can refer to the image below to get a better understanding of multivariate outliers.\n",
        "\n",
        "The major approaches to the treatment of outliers can include:\n",
        "\n",
        "- Imputation\n",
        "\n",
        "- Deletion of outliers\n",
        "\n",
        "- Binning of values\n",
        "\n",
        "- Capping the outliers\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HfmU5cpQdosB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5. Standardising Values**\n",
        "\n",
        "from rows and columns, we move to clean and fix the value of individal cell.\n",
        "\n",
        "**Steps to follow for standardising the numeric values**\n",
        "\n",
        "- **Standardise units**: Ensure all observations under one variable are expressed in a common and consistent unit, e.g., convert lbs to kg, miles/hr to km/hr, etc.\n",
        "\n",
        "- **Scale values if required**: Make sure all the observations under one variable have a common scale.\n",
        "\n",
        "- **Standardise precision** for a better presentation of data, e.g., change 4.5312341 kg to 4.53 kg.\n",
        "\n",
        "**Steps to follow for standardising the text values**\n",
        "\n",
        "- **Remove extra characters** such as common prefixes/suffixes, leading/trailing/multiple spaces, etc. These are irrelevant to the analysis.\n",
        "\n",
        "- **Standardise case**: String variables may take various casing styles, e.g., FULLCAPS, lowercase, Title Case, Sentence case, etc.\n",
        "\n",
        "- **Standardise format**: It is important to standardise the format of other elements such as date, name, etc. For example, change 23/10/16 to 2016/10/23, “Modi, Narendra” to “Narendra Modi\", etc."
      ],
      "metadata": {
        "id": "cS0lDPLfyD5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **6. Fixing Invalid Values and Filter Data**\n",
        "\n",
        "If your data set has invalid values, and if you do not know which accurate values could replace the invalid values, then it is recommended that you treat these values as missing. \n",
        "\n",
        "Now, let’s summarise what you learnt about fixing invalid values in a data set. Given below is a list of points that we covered. You could use this as a checklist for future data cleaning exercises:\n",
        "\n",
        "- **Encode unicode properly**: In case the data is being read as junk characters, try to change the encoding, for example, use CP1252 instead of UTF-8.\n",
        "\n",
        "- **Convert incorrect data types**: Change the incorrect data types to the correct data types for ease of analysis. For example, if numeric values are stored as strings, then it would not be possible to calculate metrics such as mean, median, etc. Some of the common data type corrections include changing a string to a number (\"12,300\" to “12300”), a string to a date (\"2013-Aug\" to “2013/08”), a number to a string (“PIN Code 110001” to \"110001\"), etc.\n",
        "\n",
        "- **Correct the values that lie beyond the range**: If some values lie beyond the logical range, for example, temperature less than -273° C (0° K), then you would need to correct those values as required. A close look at the data set would help you determine whether there is scope for correction or the value needs to be removed.\n",
        "\n",
        "- **Correct the values not belonging in the list**: Remove the values that do not belong to a list. For example, in a data set of blood groups of individuals, strings ‘E’ or ‘F’ are invalid values and can be removed."
      ],
      "metadata": {
        "id": "RiBa-GMZVuXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **7. Filtering the Data**\n",
        "\n",
        "It is important for you to understand what you need in order to draw insights from the data, and then choose relevant parts of the dataset for your analysis. Thus, you need to filter the data in order to get what you need for your analysis.\n",
        "\n",
        "You could use below points as a checklist for filtering data:\n",
        "\n",
        "- **Deduplicate data**: Remove identical rows and the rows in which some columns are identical.\n",
        "\n",
        "- **Filter rows**: Filter rows by segment and date period to obtain only rows relevant to the analysis.\n",
        "\n",
        "- **Filter columns**: Filter columns relevant to the analysis.\n",
        "\n",
        "- **Aggregate data**: Group by the required keys and aggregate the rest."
      ],
      "metadata": {
        "id": "eWJAG0JBpZiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **C. Univariate Analysis**\n",
        "\n",
        "Univariate analysis involves the analysis of a single variable at a time.\n",
        "\n",
        "The concept of univariate analysis is divided into **ordered** and **unordered** category of variables.\n",
        "\n",
        "**Unordered data** is the type of data that does not have any measurable terms (measurable terms can be like high-low, more-less, fail-pass, etc.) Example:\n",
        "\n",
        "The type of loan taken by an individual (home loan, personal loan, auto loan, etc.) does not have any ordered notion. They are just different types of loans.\n",
        "\n",
        "Departments of an organisation — Sales, Marketing, HR — are different departments in an organization, with no measurable attribute attached to any term.\n",
        "\n",
        "Unordered variables also called Nominal variables.\n",
        "\n",
        "**Ordered variables** are those variables that follow a natural rank of order. Some examples\n",
        "\n",
        "  - Age group:  <30, 30-40, 40-50 and so on\n",
        "\n",
        "  - Month: Jan, Feb, Mar, etc.\n",
        "\n",
        "  - Education: primary, secondary and so on\n",
        "\n",
        "\n",
        "#### Note -\n",
        "\n",
        "Both standard deviation and interquartile difference are used to represent the spread of the data.\n",
        "\n",
        "The interquartile difference is a much better metric than standard deviation if there are outliers in the data because the standard deviation will be influenced by outliers, while the interquartile difference will simply ignore them.\n",
        "  "
      ],
      "metadata": {
        "id": "BeHoWa9gplLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **D. Bivariate And Multivariate Analysis**"
      ],
      "metadata": {
        "id": "MryoLh9eqtap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Analysis Between Two Numeric Variables**\n",
        "\n",
        "Plot Types can be used - \n",
        "\n",
        "1. Correlation Matrix (heatmap)\n",
        "2. Scatter Plot\n",
        "3. Pair Plot\n",
        "\n",
        "Coorelation matrix shows the relationship between 2 vaiables(columns) through correlation coefficient.\n",
        "\n",
        "**Correlation Coefficient** depicts only a linear relationship between the numeric variables. It doesn't depict any other relationship between variables.\n",
        "\n",
        "A zero doesn't imply that there is no relationship between variables, it merely indicates that there is no linear relationship between them.\n",
        "\n",
        "A negative correlation means that if the value of the one variable increases, the value of another decreases, where it is the opposite for the positive correlation.\n",
        "\n",
        "However, the correlation matrix has its own limitations where you cannot see the exact distribution of a variable with another numeric variable. To solve this problem, we use pair plots. Pair plots are scatter plots of all numeric variables in a data set. It shows the exact variation of one variable with respect to the others.\n",
        "\n",
        "### *A high correlation coefficient does not imply that there will be a correlation with another numeric variable every time because there can be **no causation** between them. There may be cases where you will see a high correlation coefficient between two variables but there is no relation between them.*"
      ],
      "metadata": {
        "id": "325Aki8ATcQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. Correlation vs Causation**\n",
        "\n",
        "Correlation does not imply causation."
      ],
      "metadata": {
        "id": "9_E3-8Uuq4BC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. Numerical - Categorical Analysis**\n",
        "\n"
      ],
      "metadata": {
        "id": "IEMlU_dlu05q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4. Categorical - Categorical Analysis**"
      ],
      "metadata": {
        "id": "oa83mZkAJxUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5. Multivariate Analysis**"
      ],
      "metadata": {
        "id": "WSlQZVYNYbrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary**\n",
        "\n",
        "Exploratory Data Analysis (EDA) helps a data analyst to look beyond the data. It is a never-ending process—the more you explore the data, the more the insights you draw from it.  As a data analyst, almost 80% of your time will be spent understanding data and solving various business problems through EDA. If you understand EDA properly, that will be half the battle won.\n",
        "\n",
        " \n",
        "\n",
        "Now, one thing that you should keep in mind is that EDA is far more than plain visualisation. It is an end-to-end process to analyse a data set and prepare it for model-building.\n",
        "\n",
        " \n",
        "\n",
        "The four most crucial steps in any kind of data analysis. These steps include the following:\n",
        "\n",
        "- Gather data for analysis: In the data sourcing part, you learnt about the various sources of data. There are majorly two types of data sources, namely, public data and private data. Private data is associated with some security and privacy concerns, whereas public data is freely available to use without any restrictions on access or usage. There are many websites that provide access public data set available. You have also learnt about the basics of web scraping—a process to fetch the data from a web page directly.\n",
        "\n",
        "- Preparation and cleaning of data: In the cleaning process, the main objective is to remove irregularities from a data set. There are many ways to clean data, but the two most important approaches that you learnt as part of the cleaning step are treatment of missing values and outlier handling. \n",
        " \n",
        "\n",
        "Now, there are many ways to deal with missing values, for example, removing an entire column or rows with missing values; however, you need to keep in mind that it should not hamper the data with loss of information. The other method to deal with missing values is to just impute them with other values such as mean, median, mode or quantiles. The third method is to treat the missing values as a separate category; this is the safest method to deal with missing values.\n",
        "\n",
        " \n",
        "\n",
        "The different methods for analysing variables. These methods include the following:\n",
        "\n",
        "- Univariate analysis: Univariate analysis involves the analysis of a single variable at a time. Now, there are multiple types of variables, such as categorical ordered and unordered variables, and numerical variables. A univariate analysis gives insights about a single variable and how it varies, and what the counts of each and every category in it are.\n",
        "\n",
        "- Bivariate and multivariate analysis: Bivariate/multivariate analysis involves analysing two or more variables at the same time. These analyses yield very specific insights about a data set. You can infer various findings through bivariate analysis.\n",
        " "
      ],
      "metadata": {
        "id": "MgtQLI4PZWDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YFnN59Ufk3Rm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}